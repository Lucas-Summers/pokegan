{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PokéGAN Training on Google Colab\n",
        "\n",
        "This notebook trains a DCGAN to generate Pokémon images using Google Colab's GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install torch torchvision torchmetrics[image] pyyaml matplotlib scipy tensorboard datasets torch-fidelity kaggle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Clone Repository\n",
        "\n",
        "This step automatically clones the project repository from GitHub.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "repo_name = 'CSC487-Project'\n",
        "repo_url = 'https://github.com/BraedenAlonge/CSC487-Project.git'\n",
        "\n",
        "# Clone or pull repository\n",
        "if not os.path.exists(repo_name):\n",
        "    print(\"Cloning repository...\")\n",
        "    !git clone {repo_url}\n",
        "else:\n",
        "    print(\"Repository already exists. Updating...\")\n",
        "    %cd {repo_name}\n",
        "    !git pull\n",
        "    %cd ..\n",
        "\n",
        "# Move into project directory\n",
        "if repo_name in os.listdir('.'):\n",
        "    %cd {repo_name}\n",
        "    \n",
        "print(f\"Current directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Verify GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Mount Google Drive (Optional - for saving checkpoints)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Download Dataset (Kaggle Method)\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from google.colab import files\n",
        "\n",
        "print(\"--- Upload Kaggle JSON ---\")\n",
        "print(\"Please upload your kaggle.json file (from Kaggle Account -> API):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Setup Kaggle Auth\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/ 2>/dev/null\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"Downloading from Kaggle...\")\n",
        "!kaggle datasets download -d noodulz/pokemon-dataset-1000 --force\n",
        "\n",
        "# Clean previous data\n",
        "if os.path.exists('data/pokemon-dataset-1000'):\n",
        "    shutil.rmtree('data/pokemon-dataset-1000')\n",
        "!mkdir -p data\n",
        "\n",
        "print(\"Extracting dataset...\")\n",
        "if os.path.exists('pokemon-dataset-1000.zip'):\n",
        "    # Unzip to a temporary location first to inspect structure\n",
        "    temp_extract_dir = 'data/temp_extract'\n",
        "    if os.path.exists(temp_extract_dir): shutil.rmtree(temp_extract_dir)\n",
        "    !unzip -q pokemon-dataset-1000.zip -d {temp_extract_dir}\n",
        "    \n",
        "    print(\"Organizing dataset...\")\n",
        "    # Target directories\n",
        "    base_data_dir = 'data/pokemon-dataset-1000'\n",
        "    train_dir = os.path.join(base_data_dir, 'train')\n",
        "    val_dir = os.path.join(base_data_dir, 'val')\n",
        "    test_dir = os.path.join(base_data_dir, 'test')\n",
        "    \n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(val_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "    \n",
        "    # Find ALL images recursively\n",
        "    all_images = []\n",
        "    for root, dirs, files in os.walk(temp_extract_dir):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                all_images.append(os.path.join(root, file))\n",
        "    \n",
        "    print(f\"Found {len(all_images)} images total.\")\n",
        "    \n",
        "    # Shuffle and Split\n",
        "    random.shuffle(all_images)\n",
        "    train_split = int(0.9 * len(all_images))\n",
        "    val_split = int(0.05 * len(all_images))\n",
        "    \n",
        "    train_imgs = all_images[:train_split]\n",
        "    val_imgs = all_images[train_split:train_split+val_split]\n",
        "    test_imgs = all_images[train_split+val_split:]\n",
        "    \n",
        "    print(\"Moving files to train/val/test folders...\")\n",
        "    # Helper to move files\n",
        "    def move_files(file_list, target_folder):\n",
        "        for src in file_list:\n",
        "            dst = os.path.join(target_folder, os.path.basename(src))\n",
        "            # Handle duplicate filenames if flattened\n",
        "            if os.path.exists(dst):\n",
        "                base, ext = os.path.splitext(os.path.basename(src))\n",
        "                dst = os.path.join(target_folder, f\"{base}_{random.randint(0,9999)}{ext}\")\n",
        "            shutil.move(src, dst)\n",
        "            \n",
        "    move_files(train_imgs, train_dir)\n",
        "    move_files(val_imgs, val_dir)\n",
        "    move_files(test_imgs, test_dir)\n",
        "    \n",
        "    # Cleanup temp\n",
        "    shutil.rmtree(temp_extract_dir)\n",
        "    \n",
        "    print(f\"✓ Dataset prepared!\")\n",
        "    print(f\"  Train: {len(os.listdir(train_dir))}\")\n",
        "    print(f\"  Val: {len(os.listdir(val_dir))}\")\n",
        "    print(f\"  Test: {len(os.listdir(test_dir))}\")\n",
        "else:\n",
        "    print(\"Error: pokemon-dataset-1000.zip not found! Upload failed?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This cell verifies and repairs the project structure to prevent ImportErrors.\n",
        "# It automatically creates 'data/__init__.py' and 'data/pokemon_dataset.py' if they are missing.\n",
        "\n",
        "import yaml\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Get current directory and ensure it's in Python path\n",
        "project_dir = os.getcwd()\n",
        "if project_dir not in sys.path:\n",
        "    sys.path.insert(0, project_dir)\n",
        "\n",
        "print(f\"Project directory: {project_dir}\")\n",
        "\n",
        "# 1. FIX: Ensure data package has __init__.py\n",
        "data_init_path = os.path.join(project_dir, 'data', '__init__.py')\n",
        "os.makedirs(os.path.join(project_dir, 'data'), exist_ok=True)\n",
        "if not os.path.exists(data_init_path):\n",
        "    print(\"Creating missing data/__init__.py...\")\n",
        "    with open(data_init_path, 'w') as f:\n",
        "        f.write(\"from .pokemon_dataset import PokemonDataset\\n\")\n",
        "        f.write(\"__all__ = ['PokemonDataset']\\n\")\n",
        "\n",
        "# 2. FIX: Ensure pokemon_dataset.py exists (in case clone failed)\n",
        "dataset_py_path = os.path.join(project_dir, 'data', 'pokemon_dataset.py')\n",
        "if not os.path.exists(dataset_py_path):\n",
        "    print(\"⚠ data/pokemon_dataset.py missing! Creating default version...\")\n",
        "    # Write the content of pokemon_dataset.py here directly\n",
        "    code = \"\"\"\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class PokemonDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, augment=False):\n",
        "        self.root_dir = root_dir\n",
        "        self.image_paths = []\n",
        "        for root, dirs, files in os.walk(root_dir):\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    self.image_paths.append(os.path.join(root, file))\n",
        "        print(f'Found {len(self.image_paths)} images in {root_dir}')\n",
        "        \n",
        "        base_transforms = [\n",
        "            transforms.Resize((64, 64)),\n",
        "            transforms.Lambda(self._rgba_to_rgb),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ]\n",
        "        if augment:\n",
        "            aug = [\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.ColorJitter(0.1, 0.1, 0.1, 0.05)\n",
        "            ]\n",
        "            self.transform = transforms.Compose(aug + base_transforms)\n",
        "        else:\n",
        "            self.transform = transforms.Compose(base_transforms)\n",
        "            \n",
        "        if transform: self.transform = transform\n",
        "\n",
        "    def _rgba_to_rgb(self, img):\n",
        "        if img.mode == 'RGBA':\n",
        "            bg = Image.new('RGB', img.size, (255, 255, 255))\n",
        "            bg.paste(img, mask=img.split()[3])\n",
        "            return bg\n",
        "        return img.convert('RGB')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            img = Image.open(self.image_paths[idx])\n",
        "            return self.transform(img)\n",
        "        except Exception as e:\n",
        "            print(f'Error loading {self.image_paths[idx]}: {e}')\n",
        "            return torch.zeros(3, 64, 64)\n",
        "\"\"\"\n",
        "    with open(dataset_py_path, 'w') as f:\n",
        "        f.write(code)\n",
        "    print(\"✓ Created data/pokemon_dataset.py\")\n",
        "\n",
        "# Verify imports\n",
        "try:\n",
        "    import data\n",
        "    from data import PokemonDataset\n",
        "    print(\"✓ Imported PokemonDataset successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"⚠ Import Error: {e}\")\n",
        "\n",
        "# Read baseline config\n",
        "with open('configs/baseline.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Update paths for Colab\n",
        "config['data']['train_dir'] = f'{project_dir}/data/pokemon-dataset-1000/train'\n",
        "config['data']['val_dir'] = f'{project_dir}/data/pokemon-dataset-1000/val'\n",
        "config['data']['test_dir'] = f'{project_dir}/data/pokemon-dataset-1000/test'\n",
        "\n",
        "# Save Colab config\n",
        "os.makedirs('configs', exist_ok=True)\n",
        "with open('configs/colab.yaml', 'w') as f:\n",
        "    yaml.dump(config, f)\n",
        "\n",
        "print(\"Configuration updated for Colab!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Fix Python Path (If Import Errors Occur)\n",
        "\n",
        "**Run this if you get import errors:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix Python path to ensure imports work\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add current directory to Python path\n",
        "current_dir = os.getcwd()\n",
        "if current_dir not in sys.path:\n",
        "    sys.path.insert(0, current_dir)\n",
        "\n",
        "# Verify data module can be imported\n",
        "try:\n",
        "    from data import PokemonDataset\n",
        "    print(\"✓ Successfully imported PokemonDataset\")\n",
        "except ImportError:\n",
        "    # Try alternative import\n",
        "    try:\n",
        "        from data.pokemon_dataset import PokemonDataset\n",
        "        print(\"✓ Successfully imported PokemonDataset (alternative method)\")\n",
        "    except ImportError as e:\n",
        "        print(f\"⚠ Import error: {e}\")\n",
        "        print(\"   Make sure you're in the project root directory!\")\n",
        "        print(f\"   Current directory: {current_dir}\")\n",
        "        print(f\"   Files in current dir: {os.listdir('.')[:10]}\")\n",
        "\n",
        "print(f\"\\nPython path: {sys.path[:3]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Test Setup (Optional)\n",
        "\n",
        "**Note:** This step checks if everything is set up correctly. If the dataset check fails, that's OK - the dataset will be verified when training starts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CRITICAL: Fix Python path before running test_setup.py\n",
        "import sys\n",
        "import os\n",
        "current_dir = os.getcwd()\n",
        "if current_dir not in sys.path:\n",
        "    sys.path.insert(0, current_dir)\n",
        "\n",
        "# Test import first\n",
        "print(\"Testing import before running test_setup.py...\")\n",
        "try:\n",
        "    from data import PokemonDataset\n",
        "    print(\"✓ Import successful! Running test_setup.py...\\n\")\n",
        "except ImportError as e:\n",
        "    print(f\"⚠ Import failed: {e}\")\n",
        "    print(\"Trying alternative...\")\n",
        "    try:\n",
        "        from data.pokemon_dataset import PokemonDataset\n",
        "        print(\"✓ Import successful (alternative)! Running test_setup.py...\\n\")\n",
        "    except ImportError as e2:\n",
        "        print(f\"✗ Import still failing: {e2}\")\n",
        "        print(f\"Current dir: {current_dir}\")\n",
        "        print(f\"Files: {os.listdir('.')[:10]}\")\n",
        "        print(\"\\nSkipping test_setup.py - will verify during training\")\n",
        "        import sys\n",
        "        sys.exit(0)\n",
        "\n",
        "# Run test setup\n",
        "!python test_setup.py 2>&1 || echo \"Test completed (some warnings OK)\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Run Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python train.py --config configs/colab.yaml\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: View Training Progress (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View TensorBoard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Evaluate Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python eval.py --checkpoint checkpoints/baseline.pt --config configs/colab.yaml\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Download Results (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download best model\n",
        "files.download('checkpoints/best_model.pt')\n",
        "\n",
        "# Download sample images\n",
        "# files.download('outputs/epoch_0_fake.png')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
