# Stage 3: Final Model Configuration

# Model architecture
model:
  nz: 100              # Size of input noise vector
  ngf: 512             # Number of generator features in first layer
  ndf: 64              # Number of discriminator features in first layer
  nc: 3                # Number of channels (RGB)
  use_spectral_norm: true  # Apply spectral normalization to discriminator (stabilizes training)

# Data configuration
data:
  train_dir: "data/pokemon-dataset-1000/train"  # Path to training data directory
  val_dir: "data/pokemon-dataset-1000/val"      # Path to validation data
  test_dir: "data/pokemon-dataset-1000/test"    # Path to test data (for evaluation)
  num_workers: 4                                # Number of data loading workers
  augment: true                                 # Whether to apply data augmentation (horizontal flips, rotations, color jitter)

# Training configuration
training:
  seed: 42                   # Random seed for reproducibility
  deterministic: false       # Enable deterministic operations (slower)
  batch_size: 128            # Batch size (increased for more stable gradients)
  epochs: 200                # Number of training epochs
  lr_g: 0.0002               # Learning rate for generator
  lr_d: 0.0001               # Learning rate for discriminator (TTUR: lower LR for D)
  beta1: 0.5                 # Beta1 for Adam optimizer
  beta2: 0.999               # Beta2 for Adam optimizer
  label_smoothing: 0.1       # Label smoothing
  
  # Training stability options
  d_steps_per_g_step: 1      # Number of discriminator updates per generator update (1 = balanced)
  grad_clip_g: 10.0          # Gradient clipping for generator (omit to disable)
  # grad_clip_d: 10.0        # Gradient clipping for discriminator (omit to disable)
  
  # Early stopping configuration
  early_stopping:
    enabled: true             # Enable early stopping based on FID
    patience: 10             # Number of epochs to wait for improvement before stopping
    min_delta: 0.0           # Minimum change to qualify as improvement
  
  # Logging and checkpointing
  log_interval: 50           # Log every N batches
  save_interval: 5           # Save sample images every N epochs
  checkpoint_interval: 25    # Save checkpoint every N epochs
  val_samples: 64            # Number of samples for validation visualization
  
  # Directories
  checkpoint_dir: "checkpoints"
  output_dir: "outputs"
  log_dir: "logs"

